{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JndnmDMp66FL"
   },
   "source": [
    "##### Copyright 2018 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hMqWDc_m6rUC"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNqKk1MmrakH"
   },
   "source": [
    "# Spatial Attribution -- Building Blocks of Interpretability\n",
    "\n",
    "This colab notebook is part of our **Building Blocks of Intepretability** series exploring how intepretability techniques combine together to explain neural networks. If you haven't already, make sure to look at the [**corresponding paper**](https://distill.pub/2018/building-blocks) as well!\n",
    "\n",
    "This notebook demonstrates **Spatial Attribution**, a technique for exploring how detectors a different spatial positions in the network effected its output.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/lucid-static/building-blocks/notebook_heroes/spatial-attribution.jpeg\" width=\"648\"></img>\n",
    "\n",
    "<br>\n",
    "\n",
    "This tutorial is based on [**Lucid**](https://github.com/tensorflow/lucid), a network for visualizing neural networks. Lucid is a kind of spiritual successor to DeepDream, but provides flexible abstractions so that it can be used for a wide range of interpretability research.\n",
    "\n",
    "**Note**: The easiest way to use this tutorial is [as a colab notebook](), which allows you to dive in with no setup. We recommend you enable a free GPU by going:\n",
    "\n",
    "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n",
    "\n",
    "Thanks for trying Lucid!\n",
    "\n",
    "#### **This notebook is a Jupyter version of the original Google Colab Notebook. This version adds widgets to facilitate the use of Lucid on your own images.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hOBBuzMaxU37"
   },
   "source": [
    "# Install / Import / Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UL1yOZtjqkcj"
   },
   "source": [
    "This code depends on [Lucid](https://github.com/tensorflow/lucid) (our visualization library), and [svelte](https://svelte.technology/) (a web framework). The following cell will install both of them, and dependancies such as TensorFlow. And then import them as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6441,
     "status": "ok",
     "timestamp": 1520296700305,
     "user": {
      "displayName": "Christopher Olah",
      "photoUrl": "//lh5.googleusercontent.com/-GhJP0RTFLEs/AAAAAAAAAAI/AAAAAAAAEZ8/wDVK-lwJYfA/s50-c-k-no/photo.jpg",
      "userId": "104171973056281402320"
     },
     "user_tz": 480
    },
    "id": "AA17rJBLuyYH",
    "outputId": "0e52d903-dbfa-4b20-ab3c-00a242061c63"
   },
   "outputs": [],
   "source": [
    "# !npm install -g svelte-cli@2.2.0\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "# uncomment to avoid deprecation warnings :\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "tf.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.misc.io import show\n",
    "import lucid.optvis.render as render\n",
    "from lucid.misc.io import show, load\n",
    "from lucid.misc.io.reading import read\n",
    "from lucid.misc.io.showing import _image_url\n",
    "from lucid.misc.gradient_override import gradient_override_map\n",
    "import lucid.scratch.web.svelte as lucid_svelte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cUPBCRyG9xE"
   },
   "source": [
    "# Attribution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FWHqimIqk2Bs"
   },
   "outputs": [],
   "source": [
    "model = models.InceptionV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xIDcG0vjaDtk"
   },
   "outputs": [],
   "source": [
    "labels_str = read(\"https://gist.githubusercontent.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57/raw/aa66dd9dbf6b56649fa3fab83659b2acbf3cbfd1/map_clsloc.txt\",mode='r')\n",
    "labels = [line[line.find(\" \"):].strip() for line in labels_str.split(\"\\n\")]\n",
    "labels = [label[label.find(\" \"):].strip().replace(\"_\", \" \") for label in labels]\n",
    "labels = sorted([\"dummy\"] + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "p1S73WcbKIdI"
   },
   "outputs": [],
   "source": [
    "def raw_class_spatial_attr(model, img, layer, label, override=None):\n",
    "    \"\"\"\n",
    "    How much did spatial positions at a given layer effect a output class?\n",
    "    Returns:\n",
    "      array containing attributions of layer 1 on layer2 where array[i,j] is\n",
    "      the influence of layer1 on spatial posittion (i,j) of layer 2.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up a graph for doing attribution...\n",
    "    with tf.Graph().as_default(), tf.Session(), gradient_override_map(override or {}):\n",
    "        t_input = tf.placeholder_with_default(img, [None, None, 3])\n",
    "        T = render.import_model(model, t_input, t_input)\n",
    "\n",
    "        # Compute activations\n",
    "        acts = T(layer).eval()\n",
    "\n",
    "        if label is None: return np.zeros(acts.shape[1:-1])\n",
    "\n",
    "        # Compute gradient between current layer and output score\n",
    "        score = T(\"softmax2_pre_activation\")[0, labels.index(label)]\n",
    "\n",
    "        t_grad = tf.gradients([score], [T(layer)])[0] \n",
    "        grad = t_grad.eval({T(layer) : acts})\n",
    "\n",
    "        # Linear approximation of effect of spatial position\n",
    "        return np.sum(acts * grad, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v_jkx5Niji4Q"
   },
   "outputs": [],
   "source": [
    "def raw_spatial_spatial_attr(model, img, layer1, layer2, override=None):\n",
    "    \"\"\"Attribution between spatial positions in two different layers.\n",
    "    \"\"\"\n",
    "    # Set up a graph for doing attribution...\n",
    "    with tf.Graph().as_default(), tf.Session(), gradient_override_map(override or {}):\n",
    "        t_input = tf.placeholder_with_default(img, [None, None, 3])\n",
    "        T = render.import_model(model, t_input, t_input)\n",
    "\n",
    "        # Compute activations\n",
    "        acts1 = T(layer1).eval()\n",
    "        acts2 = T(layer2).eval({T(layer1) : acts1})\n",
    "\n",
    "        # Construct gradient tensor\n",
    "        # Backprop from spatial position (n_x, n_y) in layer2 to layer1.\n",
    "        n_x, n_y = tf.placeholder(\"int32\", []), tf.placeholder(\"int32\", [])\n",
    "        # channelwise magnitude of layer2 activation for each spatial position:\n",
    "        layer2_mags = tf.sqrt(tf.reduce_sum(T(layer2)**2, -1))[0]\n",
    "        score = layer2_mags[n_x, n_y]\n",
    "        t_grad = tf.gradients([score], [T(layer1)])[0]\n",
    "\n",
    "        # Compute attribution backwards from each position in layer2\n",
    "        attrs = [] #\n",
    "        for i in range(acts2.shape[1]):\n",
    "            attrs_ = []\n",
    "            for j in range(acts2.shape[2]):\n",
    "                grad = t_grad.eval({n_x : i, n_y : j, T(layer1) : acts1})\n",
    "                # linear approximation of impact (summed on channel dimension)\n",
    "                attr = np.sum(acts1 * grad, -1)[0]\n",
    "                attrs_.append(attr)\n",
    "            attrs.append(attrs_)\n",
    "        return np.asarray(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OrlLGkWxKpmf"
   },
   "outputs": [],
   "source": [
    "def orange_blue(a,b,clip=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    a: spatial position - class gradients array of shape (y_dim, x_dim) of the current layer for class A\n",
    "    b: spatial position - class gradients array of shape (y_dim, x_dim) of the current layer for class B\n",
    "    clip: whether to clip negative gradients for a and b\n",
    "    \n",
    "    Returns:\n",
    "      Heatmap of the image for both classes A and B.\n",
    "          Red channel is for A, Green channel is the mean influence of both classes\n",
    "          and blue channel is for B.\n",
    "    \"\"\"\n",
    "    \n",
    "    if clip: # keeping positive values only\n",
    "        a,b = np.maximum(a,0), np.maximum(b,0)\n",
    "    arr = np.stack([a, (a + b)/2., b], -1)\n",
    "    arr /= 1e-2 + np.abs(arr).max()/1.5\n",
    "    arr += 0.3 \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ku6hGbYmiQNI"
   },
   "source": [
    "# Spatial Attribution Interface\n",
    "\n",
    "In this section, we build the *interface* for interacting with the different kinds of spatial attribution data that we can compute using the above functions. Feel free to skip over this if you aren't interested in that part. The main reason we're including it is so that you can change the interface if you want to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1520296735140,
     "user": {
      "displayName": "Christopher Olah",
      "photoUrl": "//lh5.googleusercontent.com/-GhJP0RTFLEs/AAAAAAAAAAI/AAAAAAAAEZ8/wDVK-lwJYfA/s50-c-k-no/photo.jpg",
      "userId": "104171973056281402320"
     },
     "user_tz": 480
    },
    "id": "X6TFCwbQhre2",
    "outputId": "c53be0ec-3588-4282-d6ce-9bae16f939bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to build svelte component from html...\n",
      "svelte compile --format iife /tmp/svelte_0f883yoj/SpatialWidget_a5fb8c7f_0cb5_45d2_912b_6f11532bd357.html > /tmp/svelte_0f883yoj/SpatialWidget_a5fb8c7f_0cb5_45d2_912b_6f11532bd357.js\n",
      "Svelte build failed! Output:\n",
      "svelte version 1.64.1\n",
      "compiling ../../../../../../../tmp/svelte_0f883yoj/SpatialWidget_a5fb8c7f_0cb5_45d2_912b_6f11532bd357.html...\n",
      "Identifier is expected\n",
      "62:     position: absolute;\n",
      "63:     left: 0px;\n",
      "64:     top: 0px; {{#replace with -14px for Jupyter Classic}}\n",
      "                  ^\n",
      "65:     width: 224px;\n",
      "66:   }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%html_define_svelte SpatialWidget\n",
    "\n",
    "<div class=\"figure\" style=\"width: 500px; height: 250px; contain: strict;\">\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint1 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <svg class=\"pointer_container\" viewBox=\"0 0 {{size1}} {{size1}}\">\n",
    "      {{#each xs1 as x}}\n",
    "      {{#each ys1 as y}}\n",
    "        <rect x={{x}} y={{y}} width=1 height=1\n",
    "          class={{(pos2 != undefined && x == pos2[0] && y == pos2[1])? \"selected\" : \"\"}}\n",
    "          on:mouseover=\"set({pos2: [x,y], pos1: undefined})\"></rect>\n",
    "      {{/each}}\n",
    "      {{/each}}\n",
    "    </svg> \n",
    "\n",
    "    <div class=\"label\">{{layer1}}</div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos1: undefined})\">\n",
    "    <img class=\"img\" src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos2 == undefined)? hint2 : spritemap2[pos2[1]][pos2[0]]}}\">\n",
    "\n",
    "    <svg class=\"pointer_container\" viewBox=\"0 0 {{size2}} {{size2}}\">\n",
    "      {{#each xs2 as x}}\n",
    "      {{#each ys2 as y}}\n",
    "        <rect x={{x}} y={{y}} width=1 height=1\n",
    "          class={{(pos1 != undefined && x == pos1[0] && y == pos1[1])? \"selected\" : \"\"}}\n",
    "          on:mouseover=\"set({pos1: [x,y], pos2: undefined})\"></rect>\n",
    "      {{/each}}\n",
    "      {{/each}}\n",
    "    </svg> \n",
    "\n",
    "    <div class=\"label\">{{layer2}}</div>\n",
    "  </div>\n",
    "  \n",
    "</div>\n",
    "\n",
    "\n",
    "<style>\n",
    "\n",
    "  .outer{\n",
    "    width: 224px;\n",
    "    height: 224px;\n",
    "    display: inline-block;\n",
    "    margin-right: 2px;\n",
    "    position: relative;\n",
    "  }\n",
    "  .img, .pointer_container {\n",
    "    position: absolute;\n",
    "    left: 0px;\n",
    "    top: 0px;\n",
    "    width: 224px;\n",
    "    height: 224px;\n",
    "    image-rendering: pixelated; \n",
    "  }\n",
    "  .img {\n",
    "      z-index: -100;\n",
    "  }\n",
    "  .attr {\n",
    "    opacity: 0.6;\n",
    "    position: absolute;\n",
    "    left: 0px;\n",
    "    top: 0px; {{#replace with -14px for Jupyter Classic}}\n",
    "    width: 224px;\n",
    "  }\n",
    "  .outer .pointer_container  {\n",
    "    z-index: 100;\n",
    "  }\n",
    "  .pointer_container rect {\n",
    "    opacity: 0;\n",
    "  }\n",
    "  .pointer_container .selected  {\n",
    "    opacity: 1;\n",
    "    fill: none;\n",
    "    stroke: hsl(24, 100%, 50%);\n",
    "    stroke-width: 0.1px;\n",
    "  }\n",
    "  .label{\n",
    "    position: absolute;\n",
    "    left: 0px;\n",
    "    top: 226px;\n",
    "    width: 224px;\n",
    "    color: black;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "  function range(n){\n",
    "    return Array(n).fill().map((_, i) => i);\n",
    "  }\n",
    "  \n",
    "  export default {\n",
    "    data () {\n",
    "      return {\n",
    "        img: \"\",\n",
    "        hint1: \"\",\n",
    "        hint2: \"\",\n",
    "        spritemap1 : \"\",\n",
    "        size1: 1,\n",
    "        spritemap2 : \"\",\n",
    "        size2: 1,\n",
    "        pos1: undefined,\n",
    "        pos2: undefined,\n",
    "        layer1: \"\",\n",
    "        layer2: \"\"\n",
    "      };\n",
    "    },\n",
    "    computed: {\n",
    "      xs1: (size1) => range(size1),\n",
    "      ys1: (size1) => range(size1),\n",
    "      xs2: (size2) => range(size2),\n",
    "      ys2: (size2) => range(size2)\n",
    "    },\n",
    "    helpers: {range}\n",
    "  };\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zYaLZ6Kd2xGC"
   },
   "outputs": [],
   "source": [
    "def image_url_grid(grid):\n",
    "    return [[_image_url(img) for img in line] for line in grid ]\n",
    "\n",
    "\n",
    "def spatial_spatial_attr(model, img, layer1, layer2, hint_label_1=None, hint_label_2=None, override=None):\n",
    "    hint1 = orange_blue(\n",
    "      raw_class_spatial_attr(model, img, layer1, hint_label_1, override=override),\n",
    "      raw_class_spatial_attr(model, img, layer1, hint_label_2, override=override),\n",
    "      clip=True\n",
    "    )\n",
    "    hint2 = orange_blue(\n",
    "      raw_class_spatial_attr(model, img, layer2, hint_label_1, override=override),\n",
    "      raw_class_spatial_attr(model, img, layer2, hint_label_2, override=override),\n",
    "      clip=True\n",
    "    )\n",
    "\n",
    "    attrs = raw_spatial_spatial_attr(model, img, layer1, layer2, override=override)\n",
    "    attrs = attrs / attrs.max()\n",
    "\n",
    "    lucid_svelte.SpatialWidget({\n",
    "        \"spritemap1\": image_url_grid(attrs),\n",
    "        \"spritemap2\": image_url_grid(attrs.transpose(2,3,0,1)),\n",
    "        \"size1\": attrs.shape[3],\n",
    "        \"layer1\": layer1,\n",
    "        \"size2\": attrs.shape[0],\n",
    "        \"layer2\": layer2,\n",
    "        \"img\" : _image_url(img),\n",
    "        \"hint1\": _image_url(hint1),\n",
    "        \"hint2\": _image_url(hint2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67UCOiFUHJ8U"
   },
   "source": [
    "# Attribution With GradPool override hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t4_HNz7a9icq"
   },
   "outputs": [],
   "source": [
    "def blur(x, w1, w2):\n",
    "    \"\"\"Spatially blur a 4D tensor.\"\"\"\n",
    "    x_ = tf.pad(x, [(0,0), (1,1), (1,1), (0,0)], \"CONSTANT\")\n",
    "    x_jitter_hv = (x_[:, 2:, 1:-1] + x_[:, :-2, 1:-1] + x_[:, 1:-1, 2:] + x_[:, 1:-1, :-2])/4.\n",
    "    x_jitter_diag = (x_[:, 2:, 2:] + x_[:, 2:, :-2] + x_[:, :-2, 2:] + x_[:, :-2, :-2])/4.\n",
    "    return (1-w1-w2)*x + w1*x_jitter_hv + w2*x_jitter_diag\n",
    "\n",
    "def make_MaxSmoothPoolGrad(blur_hack=False):\n",
    "    \"\"\"Create a relaxed version of the MaxPool gradient.\n",
    "\n",
    "    GoogLeNet's use of MaxPooling creates a lot of gradient artifacts. This\n",
    "    function creates a fake gradient that gets rid of them, reducing distractions\n",
    "    in our UI demos.\n",
    "\n",
    "    Be very very careful about using this in real life. It hides model behavior\n",
    "    from you. This can help you see other things more clearly, but in most cases\n",
    "    you probably should do something else.\n",
    "\n",
    "    We're actively researching what's going on here.\n",
    "\n",
    "    Args:\n",
    "    blur_hack: If True, use the second less principled trick of slightly\n",
    "      blurring the gradient to get rid of checkerboard artifacts.\n",
    "\n",
    "    Returns:\n",
    "    Gradient function.\n",
    "\n",
    "    \"\"\"\n",
    "    def MaxPoolGrad(op, grad):\n",
    "        inp = op.inputs[0]\n",
    "\n",
    "        # Hack 1 (moderately principled): use a relaxation of the MaxPool grad\n",
    "        # ---------------------------------------------------------------------\n",
    "        #\n",
    "        # Construct a pooling function where, if we backprop through it,\n",
    "        # gradients get allocated proportional to the input activation.\n",
    "        # Then backpropr through that instead.\n",
    "        #\n",
    "        # In some ways, this is kind of spiritually similar to SmoothGrad\n",
    "        # (Smilkov et al.). To see the connection, note that MaxPooling introduces\n",
    "        # a pretty arbitrary discontinuity to your gradient; with the right\n",
    "        # distribution of input noise to the MaxPool op, you'd probably smooth out\n",
    "        # to this. It seems like this is one of the most natural ways to smooth.\n",
    "        #\n",
    "        # We'll probably talk about this and related things in future work.\n",
    "\n",
    "        op_args = [op.get_attr(\"ksize\"), op.get_attr(\"strides\"), op.get_attr(\"padding\")]\n",
    "        smooth_out = tf.nn.avg_pool(inp**2, *op_args)/ (1e-2+tf.nn.avg_pool(tf.abs(inp), *op_args))\n",
    "        inp_smooth_grad = tf.gradients(smooth_out, [inp], grad)[0]\n",
    "\n",
    "        # Hack 2 (if argument is set; not very principled) \n",
    "        # -------------------------------------------------\n",
    "        #\n",
    "        # Slightly blur gradient to get rid of checkerboard artifacts.\n",
    "        # Note, this really isn't principled. We're working around / hiding a bad\n",
    "        # property of the model. It should really be fixed by better model design.\n",
    "        #\n",
    "        # We do this so that the artifacts don't distract from the UI demo, but we\n",
    "        # don't endorse people doing it in real applications.\n",
    "\n",
    "        if blur_hack:\n",
    "            inp_smooth_grad = blur(inp_smooth_grad, 0.5, 0.25)\n",
    "\n",
    "        return inp_smooth_grad\n",
    "    return MaxPoolGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4KLEe280v-_z"
   },
   "outputs": [],
   "source": [
    "def compare_attrs(model, img, layer1, layer2, hint_label_1, hint_label_2):\n",
    "    print(\"Normal gradient:\\n\")\n",
    "\n",
    "    spatial_spatial_attr(model, img, layer1, layer2,\n",
    "                       hint_label_1=hint_label_1, hint_label_2=hint_label_2)\n",
    "\n",
    "    print(\"\\nSmooth MaxPool Grad:\")\n",
    "    print(\"note the subtle checkerboard patterns)\\n\")\n",
    "\n",
    "    spatial_spatial_attr(model, img, layer1, layer2,\n",
    "                       hint_label_1=hint_label_1, hint_label_2=hint_label_2,\n",
    "                       override={\"MaxPool\": make_MaxSmoothPoolGrad()})\n",
    "\n",
    "    print(\"\\nSmooth + Blur MaxPool Grad:\\n\")\n",
    "\n",
    "    spatial_spatial_attr(model, img, layer1, layer2,\n",
    "                       hint_label_1=hint_label_1, hint_label_2=hint_label_2,\n",
    "                       override={\"MaxPool\": make_MaxSmoothPoolGrad(blur_hack=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload file from local machine and select uploading path (A) or just select one file (B):\n",
      "A1) Select a file to upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dfc900eb6243e6a73f637f86a8205c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A2) Select destination for uploaded file\n",
      "B) Select file in this server\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513fc610459445edba069c4a2b433956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='.', filename='', show_hidden='False')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select the shallowest layer whose influence is being studied: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4807a0330dea4df1a28782779577d5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Layers', options=('mixed3a', 'mixed3b', 'mixed4a', 'mixed4b', 'mixed4c', 'mixed4d', 'mix…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select the deepest layer whose influence is being studied: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101ac87a992b4ea58ed0024b07c39401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Layers', index=1, options=('mixed3a', 'mixed3b', 'mixed4a', 'mixed4b', 'mixed4c', 'mixed…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select the first class  whose influence is being studied:: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c0662f132444d7ac0a5e189ca29912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Classes of documents', options=('Afghan hound', 'African chameleon', 'African crocodile'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select the second class  whose influence is being studied:: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312c076c23ac4be7b08211e7fc2cb1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Classes of documents', index=1, options=('Afghan hound', 'African chameleon', 'African c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    \"Upload file from local machine and select uploading path (A) or just select one file (B):\"\n",
    ")\n",
    "print(\"A1) Select a file to upload\")\n",
    "uploader = widgets.FileUpload(accept='', multiple=False)\n",
    "display(uploader)\n",
    "\n",
    "print(\"\\nA2) Select destination for uploaded file\")\n",
    "print(\"B) Select file in this server\")\n",
    "notebooks_root_path = \"\"\n",
    "fc = FileChooser(\".\",\n",
    "                 use_dir_icons=True,\n",
    "                 select_default=True)\n",
    "display(fc)\n",
    "\n",
    "\n",
    "layers_list = [layer.name for layer in model.layers[3:]]\n",
    "print(\"\\nSelect the shallowest layer whose influence is being studied: \")\n",
    "layers_widget = widgets.Dropdown(\n",
    "    options=layers_list,\n",
    "    value=layers_list[0],\n",
    "    description='Layers'\n",
    ")\n",
    "display(layers_widget)\n",
    "\n",
    "print(\"\\nSelect the deepest layer whose influence is being studied: \")\n",
    "layers_widget_bis = widgets.Dropdown(\n",
    "    options=layers_list,\n",
    "    value=layers_list[1],\n",
    "    description='Layers'\n",
    ")\n",
    "display(layers_widget_bis)\n",
    "\n",
    "print(\"\\nSelect the first class  whose influence is being studied:: \")\n",
    "classes_widget = widgets.Dropdown(\n",
    "    options=labels,\n",
    "    value=labels[0],\n",
    "    description='Classes of documents'\n",
    ")\n",
    "display(classes_widget)\n",
    "\n",
    "print(\"\\nSelect the second class  whose influence is being studied:: \")\n",
    "classes_widget_bis = widgets.Dropdown(\n",
    "    options=labels,\n",
    "    value=labels[1],\n",
    "    description='Classes of documents'\n",
    ")\n",
    "display(classes_widget_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if uploader.value: # upload local file to server\n",
    "    picture_name = uploader.value[0]\n",
    "    content = uploader.value[picture_name]['content'] # memoryview of the file\n",
    "    picture_path = os.path.join(fc.selected_path, picture_name)\n",
    "    with open(picture_name, 'wb') as f:\n",
    "        f.write(content)\n",
    "else: # use files already on the server\n",
    "    picture_path = fc.default_filename\n",
    "        \n",
    "layer_name_1 = layers_widget.value # layers to use semantic dictionnary on\n",
    "layer_name_2 = layers_widget_bis.value # layers to use semantic dictionnary on\n",
    "\n",
    "class_name_1 = classes_widget.value # layers to use semantic dictionnary on\n",
    "class_name_2 = classes_widget_bis.value # layers to use semantic dictionnary on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "dIpwT7tMk-t9",
    "outputId": "d049a5f8-5d1a-4d89-89da-1246d2da3a18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4> Legend : </h4><div style='color:orange;font-weight: bold;'>Afghan hound</div><div style='color:#85c1e9;font-weight: bold;'>African chameleon</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "No extension in URL: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-37595cbdfa88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicture_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mspatial_spatial_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint_label_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint_label_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lucid/misc/io/loading.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(url_or_handle, allow_unsafe_formats, cache, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecompressor_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lucid/misc/io/loading.py\u001b[0m in \u001b[0;36m_get_extension\u001b[0;34m(url_or_handle)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdecompressor_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No extension in URL: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl_or_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecompressor_ext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No extension in URL: "
     ]
    }
   ],
   "source": [
    "legend = \"<h4> Legend : </h4>\"\n",
    "legend += \"<div style='color:orange;font-weight: bold;'>%s</div>\" % class_name_1\n",
    "legend += \"<div style='color:#85c1e9;font-weight: bold;'>%s</div>\" % class_name_2\n",
    "display(HTML(legend))\n",
    "\n",
    "img = load(picture_path)\n",
    "\n",
    "spatial_spatial_attr(model, img, layer_name_1, layer_name_2, hint_label_1=class_name_1, hint_label_2=class_name_2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Spatial Attribution - Building Blocks of Interpretability",
   "provenance": [
    {
     "file_id": "1uRqpBNPg-aW3tRU-uo-mWg6cQxuAquHW",
     "timestamp": 1518822563463
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
