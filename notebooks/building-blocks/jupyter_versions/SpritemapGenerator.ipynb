{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JndnmDMp66FL"
   },
   "source": [
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hMqWDc_m6rUC"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNqKk1MmrakH"
   },
   "source": [
    "# Spritemap generation -- Building Blocks of Interpretability\n",
    "\n",
    "This colab notebook is part of our **Building Blocks of Intepretability** series exploring how intepretability techniques combine together to explain neural networks. If you haven't already, make sure to look at the [**corresponding paper**](https://distill.pub/2018/building-blocks) as well!\n",
    "\n",
    "This notebook allow to generate spritemaps used in the notebooks *Semantic dictionnary* and *Channel attribution*. This notebook is meant to be used with Jupyter lab or Jupyter notebook only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15116,
     "status": "ok",
     "timestamp": 1520312194763,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "AA17rJBLuyYH",
    "outputId": "3acd867e-4fc2-4369-8684-cbdcd3f70c7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.decomposition.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "# uncomment to avoid deprecation warnings :\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "tf.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.optvis import render, objectives, transform, param\n",
    "from lucid.misc.channel_reducer import ChannelReducer\n",
    "from lucid.misc.io import show, load, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer (belonging to InceptionV1) <conv2d0: 64> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <conv2d1: 64> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <conv2d2: 192> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <mixed3a: 256> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <mixed3b: 480> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <mixed4a: 508> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <mixed4b: 512> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <mixed4c: 512> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <mixed4d: 528> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <mixed4e: 832> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <mixed5a: 832> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <mixed5b: 1024> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <head0_bottleneck: 128> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <nn0: 1024> ([{'dense'}]),\n",
       " Layer (belonging to InceptionV1) <softmax0: 1008> ([{'dense'}]),\n",
       " Layer (belonging to InceptionV1) <head1_bottleneck: 128> ([{'conv'}]),\n",
       " Layer (belonging to InceptionV1) <nn1: 1024> ([{'dense'}]),\n",
       " Layer (belonging to InceptionV1) <softmax1: 1008> ([{'dense'}]),\n",
       " Layer (belonging to InceptionV1) <softmax2: 1008> ([{'dense'}]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.InceptionV1()\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 6 - Mixed 4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spritemap(model, layer_name, sprite_size, row_size, column_size=24):\n",
    "    param_funct = lambda : param.image(sprite_size)\n",
    "        \n",
    "    height = column_size * sprite_size\n",
    "    width = row_size * sprite_size\n",
    "    \n",
    "    neuron_sprite_map_array = np.full((height,width,3), 0.9, dtype=\"single\")\n",
    "    channel_sprite_map_array = np.full((height,width,3), 0.9, dtype=\"single\")\n",
    "    \n",
    "    for i in range(column_size):\n",
    "        top_left_y = sprite_size * i\n",
    "        for j in range(row_size):\n",
    "            top_left_x = sprite_size * j\n",
    "            unit_index = i*row_size+j\n",
    "            \n",
    "            neuron_objectif_f = objectives.neuron(layer_name, channel_n=unit_index)\n",
    "            neuron_feature_viz = render.render_vis(model, neuron_objectif_f, param_funct, verbose=False)\n",
    "            neuron_sprite_map_array[top_left_y : top_left_y+sprite_size,\n",
    "                             top_left_x : top_left_x+sprite_size,:] = neuron_feature_viz[0][0]\n",
    "            \n",
    "            channel_objectif_f = layer_name + \":\" + str(unit_index) \n",
    "            channel_feature_viz = render.render_vis(model, channel_objectif_f, param_funct, verbose=False)\n",
    "            channel_sprite_map_array[top_left_y : top_left_y+sprite_size,\n",
    "                             top_left_x : top_left_x+sprite_size,:] = channel_feature_viz[0][0]\n",
    "    \n",
    "    return neuron_sprite_map_array, channel_sprite_map_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed3a 256\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'neuron_sprite_map_nam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dabe53353b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mneuron_sprite_map_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_sprite_map_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_spritemap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msprite_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mneuron_sprite_map_nam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_sprite_map_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./spritemaps/spritemap_neuron_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_sprite_map_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./spritemaps/spritemap_channel_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neuron_sprite_map_nam' is not defined"
     ]
    }
   ],
   "source": [
    "column_size = 24\n",
    "sprite_size = 110\n",
    "\n",
    "for layer in model.layers[3:12]:\n",
    "    print(layer.name, layer.depth)\n",
    "    row_size = ceil(model.get_layer(layer.name).depth / column_size)\n",
    "    \n",
    "    neuron_sprite_map_array, channel_sprite_map_array = create_spritemap(model, layer.name, sprite_size, row_size, column_size)\n",
    "    \n",
    "    save(neuron_sprite_map_array, \"./spritemaps/spritemap_neuron_\" + layer.name.split(\"/\")[0] + \".jpeg\")\n",
    "    save(channel_sprite_map_array, \"./spritemaps/spritemap_channel_\" + layer.name.split(\"/\")[0] + \".jpeg\")\n",
    "    \n",
    "    # we use split(\"/\") to avoid  path problems with layer names containing \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
